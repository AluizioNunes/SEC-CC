#!/bin/bash
# Script para monitorar e otimizar configuraÃ§Ãµes de auto-scaling

LOG_FILE="scaling-config/autoscaling-monitor.log"

log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

# Monitorar mÃ©tricas atuais
monitor_current_metrics() {
    log "ðŸ“Š Monitorando mÃ©tricas atuais de sistema..."

    # CPU e Memory por serviÃ§o
    kubectl top pods -n production | tee -a "$LOG_FILE"

    # UtilizaÃ§Ã£o de recursos por nÃ³
    kubectl top nodes | tee -a "$LOG_FILE"

    # MÃ©tricas de negÃ³cio
    curl -s http://business-intelligence:8086/metrics | grep -E "(revenue|users|transactions)" | tee -a "$LOG_FILE"
}

# Analisar padrÃµes de uso
analyze_usage_patterns() {
    log "ðŸ” Analisando padrÃµes de uso..."

    # PadrÃµes diÃ¡rios
    echo "AnÃ¡lise de padrÃµes diÃ¡rios:" >> "$LOG_FILE"
    kubectl get hpa -n production -o yaml | grep -A 5 -B 5 "currentReplicas\|targetCPUUtilization" >> "$LOG_FILE"

    # PadrÃµes semanais
    echo "AnÃ¡lise de padrÃµes semanais:" >> "$LOG_FILE"
    kubectl get hpa -n production --sort-by=.status.lastScaleTime >> "$LOG_FILE"
}

# Otimizar configuraÃ§Ãµes de HPA
optimize_hpa_settings() {
    log "âš™ï¸ Otimizando configuraÃ§Ãµes de HPA..."

    # Ajustar thresholds baseado em padrÃµes observados
    kubectl patch hpa sec-ultra-revolutionary-hpa -n production --patch '
    spec:
      metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 65
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 75
    '

    # Atualizar polÃ­ticas de scaling
    kubectl patch hpa sec-ultra-revolutionary-hpa -n production --patch '
    spec:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 600
        scaleUp:
          stabilizationWindowSeconds: 60
    '
}

# Ajustar recursos baseado em demanda
adjust_resources() {
    log "ðŸ”§ Ajustando recursos baseado em demanda..."

    # Obter mÃ©tricas atuais
    CURRENT_PODS=$(kubectl get pods -n production --field-selector=status.phase=Running | wc -l)
    CURRENT_CPU=$(kubectl top pods -n production --no-headers | awk '{sum += $2} END {print sum}')

    # Calcular recursos necessÃ¡rios
    RECOMMENDED_PODS=$(( CURRENT_PODS + (CURRENT_PODS * 20 / 100) ))
    RECOMMENDED_CPU=$(( CURRENT_CPU + (CURRENT_CPU * 15 / 100) ))

    log "Pods atuais: $CURRENT_PODS, recomendados: $RECOMMENDED_PODS"
    log "CPU atual: ${CURRENT_CPU}m, recomendado: ${RECOMMENDED_CPU}m"

    # Aplicar ajustes se necessÃ¡rio
    if [ $RECOMMENDED_PODS -gt $CURRENT_PODS ]; then
        kubectl scale deployment sec-ultra-revolutionary -n production --replicas=$RECOMMENDED_PODS
        log "âœ… Escalonado para $RECOMMENDED_PODS rÃ©plicas"
    fi
}

# PrevisÃ£o de demanda futura
predict_future_demand() {
    log "ðŸ”® Prevendo demanda futura..."

    # Usar modelo de IA para prever demanda
    DEMAND_PREDICTION=$(curl -s "http://business-intelligence:8086/api/predict-demand?hours=24" | jq -r '.predicted_demand' 2>/dev/null || echo "100")

    # Ajustar capacidade baseada na previsÃ£o
    PREDICTED_CAPACITY=$(( DEMAND_PREDICTION * 12 / 10 )) # 20% buffer

    log "Demanda prevista: $DEMAND_PREDICTION, capacidade recomendada: $PREDICTED_CAPACITY"

    # PrÃ©-escalar se demanda prevista for alta
    if [ $PREDICTED_CAPACITY -gt $(kubectl get deployment sec-ultra-revolutionary -n production -o jsonpath='{.spec.replicas}') ]; then
        kubectl scale deployment sec-ultra-revolutionary -n production --replicas=$PREDICTED_CAPACITY
        log "âœ… PrÃ©-escalado para $PREDICTED_CAPACITY rÃ©plicas baseado em previsÃ£o"
    fi
}

# RelatÃ³rio de eficiÃªncia de scaling
generate_scaling_report() {
    log "ðŸ“‹ Gerando relatÃ³rio de eficiÃªncia de scaling..."

    cat > "scaling-config/efficiency-report-$(date +%Y%m%d).md" << EOF
# ðŸš€ RelatÃ³rio de EficiÃªncia de Auto-Scaling
## Data: $(date)
## Ambiente: ProduÃ§Ã£o

## MÃ©tricas de Performance
- **Tempo mÃ©dio de scale-up:** $(grep "scale-up" "$LOG_FILE" | tail -5 | awk '{print $3}' | awk '{sum += $1} END {print sum/NR "s"}')
- **Tempo mÃ©dio de scale-down:** $(grep "scale-down" "$LOG_FILE" | tail -5 | awk '{print $3}' | awk '{sum += $1} END {print sum/NR "s"}')
- **EficiÃªncia de CPU:** $(kubectl top nodes --no-headers | awk '{sum += $3} END {print 100 - (sum/NR) "%"}')
- **EficiÃªncia de memÃ³ria:** $(kubectl top nodes --no-headers | awk '{sum += $5} END {print 100 - (sum/NR) "%"}')

## Eventos de Scaling (Ãšltimas 24h)
$(kubectl get events --sort-by=.lastTimestamp | grep -i scaling | tail -10)

## RecomendaÃ§Ãµes de OtimizaÃ§Ã£o
1. **CPU Threshold:** Considerar reduÃ§Ã£o para 60% se aplicaÃ§Ãµes sÃ£o CPU-bound
2. **Memory Threshold:** Manter em 80% para estabilidade
3. **Scale-up Speed:** Otimizado para 50% para resposta rÃ¡pida
4. **Scale-down Delay:** 10 minutos Ã© adequado para evitar flapping

## Custos de Infraestrutura
- **Custo atual:** Estimado baseado em recursos atuais
- **OtimizaÃ§Ã£o potencial:** AtÃ© 30% com ajustes finos
- **ROI do auto-scaling:** CÃ¡lculo baseado em eficiÃªncia

## PrÃ³ximos Passos
1. Implementar machine learning para previsÃ£o de demanda
2. Configurar polÃ­ticas de scaling baseadas em mÃ©tricas de negÃ³cio
3. Integrar com sistemas de monitoramento de custos
4. Otimizar para workloads especÃ­ficos (blockchain, AI, metaverso)

---
*RelatÃ³rio gerado automaticamente em:* $(date)
